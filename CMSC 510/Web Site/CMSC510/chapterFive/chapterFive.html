<!DOCTYPE html>
<html>
<head>
<link href="../../bootstrap.min.css" rel="stylesheet" type="text/css">
<title>Chapter 5</title>
</head>
<body>
<div class="container">
<h3>Random variables</h3>
<p>A <i>discrete random variable</i> <i>X</i> is a variable that can take on a range of discrete values <i>X</i><sub>1</sub>, <i>X</i><sub>2</sub>,&#8230;,<i>X</i><sub><i>n</i></sub> with associated probabilities <i>p</i><sub>1</sub>, <i>p</i><sub>2</sub>, &#8230;<i>p</i><sub><i>n</i></sub>.</p>
<p>The expected value <i>E</i>{<i>X</i>} is given by the expression</p>
<p class="text-center"><img src="chapterFive1.png"/></p>
<p>In probability theory we also study <i>events</i>. Suppose a system can be in one of several different states. We say that an event <i>A</i> occurs when the system falls into a particular state associated with that event. In probability theory we try to compute the probability of certain events happening: suppose that we have determined that an event <i>A</i> occurs with probability <i>p</i>.</p>
<p>We can associate a special kind of random variable with an event <i>A</i>. This random variable is called an <i>indicator random variable</i> and is written <i>I</i>{<i>A</i>} or <i>X</i><sub><i>A</i></sub>. The indicator random variable has a value of 1 if <i>A</i> occurs, and 0 if it does not. Given this, we can compute the expected value of <i>X</i><sub><i>A</i></sub> =  <i>I</i>{<i>A</i>}:</p>
<p class="text-center"><i>E</i>{<i>X</i><sub><i>A</i></sub>} = <i>p</i>&#183;1 + (1-<i>p</i>)&#183;0 = <i>p</i></p>
<h3>Costs and random variables</h3>
<p>In estimating the runtime cost of a particular algorithm, we sometimes will have to deal with uncertain events. That is, we may be looking at an algorithm, or a portion of an algorithm, that exhibits a range of different behaviors (and associated costs) depending on the nature of the data we are processing. If we can quantify the range of outcomes (and their associated costs) and attach probabilities to those outcomes, we can construct a random variable for the cost. Once we have constructed an appropriate random variable to model the cost, we can use probability theory methods to compute an expected value for the cost.</p>
<p>Having said this, there is often no single best way to model a cost with a random variable. What I will attempt to do below is to show some examples that demonstrate a range of strategies for associating costs with random variables.</p>
<h3>The hiring problem</h3>
<p>In section 5.1 the authors present the hiring problem. In the hiring problem you are trying to hire a personal assistant. A personel agency has a set of <i>n</i> candidates available, and they will send you candidates one by one for you to evaluate.</p>
<p>Here are some further details.</p>
<ul>
<li>The candidates all have different qualification levels: this makes it possible for you to assign a rank to each of the candidates. No two candidates have the same rank.</li>
<li>Any time a candidate arrives whose rank is better than your current assistant, you fire your current assistant and hire the new candidate.</li>
<li>You pay a small fee <i>c</i><sub><i>i</i></sub> each time the agency sends you a candidate.</li>
<li>You pay a much higher cost <i>c</i><sub><i>h</i></sub> to fire your current assistant and hire the better candidate.</li>
<li>You hire the first candidate they send you.</li>
<li>Candidates arrive in random order of ranking.</li>
</ul>
<p>The question we want to answer is &quot;what is the expected cost of doing this interviewing and hiring process for <i>n</i> candidates?&quot;</p>
<p>We can summarize all of this in a chunk of pseudocode.</p>
<pre>
Hire-Assistant(n)
  best = 0
  for i = 1 to n
    interview candidate i
    if candidate i is better than best
      best = i
      hire candidate i
</pre>
<p>For this example we want to make a slight departure from our usual method of estimating run times. In this example we don't want to estimate a run time, but rather a total cost. We compute this total cost by attaching a cost to only some of the statements in the code.</p>
<pre>
Hire-Assistant(n)
  best = 0
  for i = 1 to n
    interview candidate i      // Cost = <i>c</i><sub><i>i</i></sub>
    if candidate i is better than best
      best = i
      hire candidate i         // Cost = <i>c</i><sub><i>h</i></sub>
</pre>
<p>The complication here is that one of our costs is associated with a probabilistic event: the hiring event does not occur on every iteration of the loop.</p>
<p>The correct way to count the cost of the hiring event is to associate it with an event and to construct a random variable that models that event. We construct an event</p>
<p class="text-center"><i>H</i><sub><i>i</i></sub> = {Candidate <i>i</i> is hired}</p>
<p>and an associated indicator random variable:</p>
<p class="text-center"><img src="chapterFive2.png"/></p>
<p>If we can compute an expected value for this random variable, we can go on to compute our total cost:</p>
<p class="text-center"><img src="chapterFive3.png"/></p>
<p>We can compute the desired expectation and finish this computation as soon as we know the probability distribution for the random variable <i>X</i><sub><i>i</i></sub>. That probability distribution hinges on a simple question: what is the probability that candidate <i>i</i> is better than the <i>i</i>-1 candidates who have come before? If we assume that all <i>i</i> candidates in question have a random rank and that the candidates arrive in random order, any one of the candidates has the same probability of being the best in the group. In particular, the last candidate has a probability 1/<i>i</i> of being the best. From this we can compute</p>
<p class="text-center"><img src="chapterFive4.png"/></p>
<p>We now see that</p>
<p class="text-center"><img src="chapterFive5.png"/></p>
<h3>The hat check problem</h3>
<p>Here is a problem from the textbook. <i>N</i> customers leave their hats at a hat check. The person operating the hat check returns the hats back to the customers in random order when they leave. What is the expected number of customers who will receive their own hat back?</p>
<p>To solve this problem we introduce a family of indicator random variables</p>
<p class="text-center"><i>H</i><sub><i>i</i></sub> = { Customer <i>i</i> gets their own hat back }</p>
<p>A simple counting argument shows that the probability <i>p</i><sub><i>i</i>,1</sub> that <i>H</i><sub><i>i</i></sub> is 1 is</p>
<p class="text-center"><img src="chapterFive6.png"/></p>
<p>There are <i>N</i>! ways to arrange the hats. Of these permutations (<i>N</i>-1)! have an <i>i</i> in position <i>i</i>.</p>
<p>The expected value of <i>H</i><sub><i>i</i></sub> is therefore</p>
<p class="text-center"><img src="chapterFive7.png"/></p>
<p>The expected number of customers who get their own hats back is</p>
<p class="text-center"><img src="chapterFive8.png"/></p>
<p>We would like to say that</p>
<p class="text-center"><img src="chapterFive9.png"/></p>
<p>The problem with this proof is that the first equality appears to depend on the random variables involved being independent. This is not the case here, because the <i>H</i><sub><i>i</i></sub> variables are not independent random variables. For example, if I tell you that <i>H</i><sub>1</sub> is 1, that information affects the probability that <i>H</i><sub>2</sub> will be 2.</p>
<p>It turns out however, that the first equality is true even though the variables are not independent. Let us consider a simpler version of the equality:</p>
<p class="text-center"><img src="chapterFive10.png"/></p>
<p>To prove this equality we consider the four possible states for the combined random variable <i>H</i><sub>1</sub> + <i>H</i><sub>2</sub> and their associated probabilities:</p>
<p class="text-center"><img src="chapterFive11.png"/></p>
<p>From this we can compute <i>E</i>{ <i>H</i><sub>1</sub> + <i>H</i><sub>2</sub> }:</p>
<p class="text-center"><img src="chapterFive12.png"/></p>
<p class="text-center"><img src="chapterFive13.png"/></p>
<p>What is going on here is an example of a more general principle called the <i>linearity of expectations</i>. Even if the variables <i>H</i><sub><i>i</i></sub> are not independent, it is still true that</p>
<p class="text-center"><img src="chapterFive14.png"/></p>
<p>You can find many proofs of this principle online. Here is <a href="https://brilliant.org/wiki/linearity-of-expectation/">one such proof</a>.</p>
<h3 id="exercise">Homework problem</h3>
<p>Consider the following variation of the hat check problem. The difference this time is that the hats have values: customer <i>i</i>'s hat has a value of $<i>i</i>. When the customers get their hats back they will complain if the hat they get back has a value less than the hat they checked. Customers who complain will demand to be paid the difference in value between the hat they checked and the hat they got back. (Customers who get back a hat with greater value will just walk off with the more valuable hat.) What is the expected amount of money the hat check will have to pay out in claims?</p>
<h3>Insertion sort</h3>
<p>Insertion sort is a slightly more complex algorithm which also requires a probabilistic runtime analysis.</p>
<p>Here is the pseudocode for insertion sort.</p>
<pre>
for j = 2 to n
  key = A[j]
  i = j - 1
  while i &gt; 0 and A[i] &gt; key
    A[i+1] = A[i]
    i = i - 1
  A[i+1] = key
</pre>
<p>A key observation to make here is that the statements in the innermost loop are probabilistic statements. Depending on the arrangement of the data, these statements may or may not get executed. As we have seen already, the appropriate way to deal with a probabilistic statement is to construct an event that says that the statement executes and then prepare a corresponding indicator random variable. In this example, the event we want to work with is</p>
<p class="text-center"><i>X</i><sub><i>j</i>,<i>i</i></sub> = {The statement runs when <i>i</i> and <i>j</i> have the given values}</p>
<p>The problem with this event is that it is hard to compute a probability for the event. In applied probability theory, we often work around problems like this by replacing the event in question with an equivalent event whose probability is easy to compute. In this case, we can get what we want by instead considering this event:</p>
<p class="text-center"><i>Y</i><sub><i>j</i>,<i>i</i></sub> = {<i>A</i>[<i>j</i>] belongs in position <i>i</i> or below}</p>
<p>The probability of this event is easy to determine. If we assume that the numbers are truly randomly distributed, then <i>A</i>[<i>j</i>] has an equal probability 1/<i>j</i> of belonging in any one of the <i>j</i> possible locations between 1 and <i>j</i>. From this we can conclude that the probability that <i>A</i>[<i>j</i>] belongs in position <i>i</i> or below is <i>i</i>/<i>j</i>. Finally, it is easy to see that the statements in the inner loop will run if and only if event <i>Y</i><sub><i>j</i>,<i>i</i></sub> takes place.</p>
<p>With these preliminaries out of the way, we are now ready to compute costs for insertion sort. Here is the code with costs attached. In cases where a statement is probabilistic, the cost is expressed as a combination of a cost with a random variable that says {the statement executes}.</p>
<pre>
for j = 2 to n               // <img src="chapterFive15.png"/> <i>c</i><sub>1</sub>
  key = A[j]                 // <img src="chapterFive16.png"/> <i>c</i><sub>2</sub>
  i = j - 1                  // <img src="chapterFive17.png"/> <i>c</i><sub>3</sub>
  while i &gt; 0 and A[i] &gt; key // <img src="chapterFive18.png"/> <img src="chapterFive19.png"/>
    A[i+1] = A[i]            // <img src="chapterFive20.png"/> <img src="chapterFive21.png"/><i>Y</i><sub><i>j</i>,<i>i</i></sub> <i>c</i><sub>5</sub>
    i = i - 1                // <img src="chapterFive22.png"/> <img src="chapterFive23.png"/><i>Y</i><sub><i>j</i>,<i>i</i></sub> <i>c</i><sub>6</sub>
  A[i+1] = key               // <img src="chapterFive24.png"/> <i>c</i><sub>7</sub>
</pre>
<p>The final step is to compute expected values for all of these costs. For costs that are not probabilistic, the cost is just the indicated sum. For example,</p>
<p class="text-center"><img src="chapterFive25.png"/></p>
<p>To compute the expectations where random variables are present we do the following:</p>
<p class="text-center"><img src="chapterFive26.png"/></p>
<p>We have now cooked things down to the point where we can compute the sum:</p>
<p class="text-center"><img src="chapterFive27.png"/></p>
<p class="text-center"><img src="chapterFive28.png"/></p>
<p class="text-center"><img src="chapterFive29.png"/></p>
<p class="text-center"><img src="chapterFive30.png"/></p>
<p class="text-center"><img src="chapterFive31.png"/></p>
<p class="text-center"><img src="chapterFive32.png"/></p>
<p class="text-center"><img src="chapterFive33.png"/></p>
</div>
</body>
</html>
